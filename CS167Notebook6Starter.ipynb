{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS167Notebook6Starter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMUDXEKsep5fpEhA3qXAwa5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/urness/CS167Notebook6/blob/main/CS167Notebook6Starter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook #6\n",
        "Name:\n"
      ],
      "metadata": {
        "id": "zqZo6gbJefy2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Description:\n",
        "Describe the problem you are going to attempt to solve\n",
        "Describe the tools used and your approach. "
      ],
      "metadata": {
        "id": "sK7vxZ2VenfW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example Code"
      ],
      "metadata": {
        "id": "dzT8QDqhfwOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Eu1oVdmgfE_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "PCkq5nMZfEc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_Mnt0ATea_Z"
      },
      "outputs": [],
      "source": [
        "#ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import keras\n",
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import sys"
      ],
      "metadata": {
        "id": "BQ2LBOmKfhqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "\n",
        "# Example code for Chest X-Ray"
      ],
      "metadata": {
        "id": "mNm7BTjafFRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dimensions of our images.\n",
        "img_width = 200\n",
        "img_height = 200\n",
        "\n",
        "#the directories where our train and test data is\n",
        "train_data_dir = '/content/drive/MyDrive/CS167Spring22/datasets/chest_xray/train' #5216 images\n",
        "test_data_dir = '/content/drive/MyDrive/CS167Spring22/datasets/chest_xray/test'   #624 images\n",
        "\n",
        "#we will feed the training images to the neural network\n",
        "#in batches of 32 images at a time so we don't have \n",
        "#to load the entire data set into memory\n",
        "batch_size = 32\n"
      ],
      "metadata": {
        "id": "DRL2RVhKfrog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# used to rescale the pixel values from [0, 255] to between 0 and 1\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "#These will look for our training and testing data\n",
        "#in their respective directory, and it will figure out\n",
        "#the class of each example based on the subfolder it is in\n",
        "train_data = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')\n",
        "\n",
        "test_data = datagen.flow_from_directory(\n",
        "        test_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary')"
      ],
      "metadata": {
        "id": "826WLAlsf3dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up CNN here"
      ],
      "metadata": {
        "id": "ff-kzhThf4nZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example code for Simpsons Data"
      ],
      "metadata": {
        "id": "9LO-B6IYf7ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dimensions of our images\n",
        "img_width = 64\n",
        "img_height = 64\n",
        "\n",
        "#the directories where our train and test data is\n",
        "train_data_dir = '/content/drive/MyDrive/CS167Spring22/datasets/SimpsonsSubsetData/train' \n",
        "test_data_dir = '/content/drive/MyDrive/CS167Spring22/datasets/SimpsonsSubsetData/test'   \n",
        "\n",
        "#we will feed the training images to the neural network\n",
        "#in batches of 32 images at a time so we don't have \n",
        "#to load the entire data set into memory\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "aCeEpD8JgHIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# used to rescale the pixel values from [0, 255] to between 0 and 1\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "#These will look for our training and testing data\n",
        "#in their respective directory, and it will figure out\n",
        "#the class of each example based on the subfolder it is in\n",
        "train_data = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_data = datagen.flow_from_directory(\n",
        "        test_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "id": "gCPDwRXdgLRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up CNN here"
      ],
      "metadata": {
        "id": "8Fw8fHiZgNFD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}