{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Day22NotesCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/urness/CS167Notebook6/blob/main/Day22NotesCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-49rU2ebgWi",
        "outputId": "17db5329-8c3a-43aa-8e6d-5a504ff57da3"
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvyRvtbiZR9C"
      },
      "source": [
        "## Enable GPUs\n",
        "Go to 'Edit' and then 'Notebook Settings'. In the 'Hardware Accelerator' dropdown menu, select 'GPU'. This means that Colab will run on a GPU from Google rather than a CPU which will accelerate our training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V99rr32GZROh",
        "outputId": "28e1e403-28bf-4692-dd21-e4a1f47fe720"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHEh6Jp_aqI-",
        "outputId": "5c247da4-5ddb-4cc7-f08b-2e1d8f1703af"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "print (\"TensorFlow version: \" + tf.__version__)\n",
        "print (\"Keras version: \" + keras.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.8.0\n",
            "Keras version: 2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mRtAHaMavg5"
      },
      "source": [
        "#ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEOuptyDazCz"
      },
      "source": [
        "# import the libraries\n",
        "import keras\n",
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following for the full data set\n",
        "Warning: the first epoch may take about 2 hours"
      ],
      "metadata": {
        "id": "I4ThiTZGIoEl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBu1WH6ya26f"
      },
      "source": [
        "# dimensions of our images. We take the images an convert them to 64x64 pixel arrays. This can be changed/tuned\n",
        "img_width = 64\n",
        "img_height = 64\n",
        "\n",
        "#the directories where our train and test data is\n",
        "train_data_dir = '/content/drive/MyDrive/CS167Spring22/datasets/animals/train' #922 images\n",
        "test_data_dir = '/content/drive/MyDrive/CS167Spring22/datasets/animals/test'   #91 images\n",
        "\n",
        "#we will feed the training images to the neural network\n",
        "#in batches of 32 images at a time so we don't have \n",
        "#to load the entire data set into memory\n",
        "batch_size = 32\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9UN16kdRWZN"
      },
      "source": [
        "# Load the data\n",
        "If you get a 'File not found' error here and you're sure your path is correct, make sure you unzipped the file. \n",
        "\n",
        "You may need to use a plugin if you want to unzip on Drive. Instead you can download it to your local machine, unzip it on your local machine and then upload to Drive. Uploading/upzipping on Drive may take a while.\n",
        "\n",
        "This code needs to be adjusted to work with categorical classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9XD_GSrbJhO",
        "outputId": "d94a3aa4-0c4f-4f8b-b63c-6ec38ff893ac"
      },
      "source": [
        "# used to rescale the pixel values from [0, 255] to between 0 and 1\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "#These will look for our training and testing data\n",
        "#in their respective directory, and it will figure out\n",
        "#the class of each example based on the subfolder it is in\n",
        "train_data = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary') ### may need to be changed\n",
        "\n",
        "test_data = datagen.flow_from_directory(\n",
        "        test_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary') ### may need to be changed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 922 images belonging to 9 classes.\n",
            "Found 91 images belonging to 9 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egPbx_xSQyTo"
      },
      "source": [
        "#setting up a CNN model here.... current setup works for 0 to 1 data \n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation = 'relu', input_shape=(img_width, img_height, 3)))\n",
        "model.add(Flatten()) #flatten the convolutional layer so it can go into a fully-connected layer\n",
        "model.add(Dense(32)) #fully-connected layer\n",
        "model.add(Dense(1,activation='sigmoid')) ### need to change this \n",
        "\n",
        "# need to compile the model before you can use it\n",
        "model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy']) ### need to change this"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMiBVry2R8dl"
      },
      "source": [
        "#This will actually train the model.\n",
        "#You will want to change the epochs to something small enough to run on your computer.\n",
        "#Maybe 3 to 10 if you do not have a GPU doing the work.\n",
        "training_results = model.fit_generator(\n",
        "        train_data, #training set\n",
        "        steps_per_epoch = len(train_data), \n",
        "        epochs=5, #number of epochs \n",
        "        validation_data = test_data, #testing set\n",
        "        validation_steps = len(test_data)\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztuazstBSAUg"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(training_results.history['accuracy'])\n",
        "plt.plot(training_results.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeHAyTm5uezi"
      },
      "source": [
        "# Now, test an image in the testing *set*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCQ1eiCkvXC2"
      },
      "source": [
        "# display the image\n",
        "from IPython.display import Image\n",
        "display(Image('/content/drive/MyDrive/CS167Spring22/datasets/animals/test/chicken/215.jpeg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3XMBtN6SJlq"
      },
      "source": [
        "\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "img = load_img(\"/content/drive/MyDrive/CS167Spring22/datasets/animals/test/chicken/215.jpeg\", target_size=(64, 64))\n",
        "\n",
        "# convert to array\n",
        "img = img_to_array(img)\n",
        "# reshape into a single sample with 3 channels\n",
        "\n",
        "img = img.reshape(1, 64, 64, 3)\n",
        "img = img.astype('float32')\n",
        "#convert image from [0,255] to [0,1]\n",
        "img = datagen.standardize(img)\n",
        "\n",
        "# predict the class\n",
        "result = model.predict(img)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMg1okPIuj6_"
      },
      "source": [
        "# get the list of possible classes from the directory\n",
        "import os\n",
        "vals = list(result[0])\n",
        "\n",
        "classes = os.listdir(\"./drive/MyDrive/CS167Spring22/datasets/animals/train/\")\n",
        "classes.sort()\n",
        "max_index = vals.index(max(vals)) # what one is best?\n",
        "print(classes[max_index])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}